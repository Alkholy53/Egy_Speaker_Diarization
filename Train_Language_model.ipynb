{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install wget\n",
    "!apt-get install -y sox libsndfile1 ffmpeg\n",
    "!pip install text-unidecode\n",
    "!pip install matplotlib>=3.3.2\n",
    "## Install NeMo\n",
    "BRANCH = 'r2.0.0rc0'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH  #egg=nemo_toolkit[all] \n",
    "## Grab the config we'll use in this example\n",
    "!mkdir configs\n",
    "!git clone https://github.com/Alkholy53/ASR-Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install editdistance\n",
    "!pip install webdataset\n",
    "!pip install pyannote.metrics\n",
    "!pip install einops\n",
    "! pip install pyannote.core\n",
    "! pip install inflect\n",
    "! pip install hydra.core\n",
    "! pip install lhotse\n",
    "!pip install numpy soundfile joblib omegaconf lhotse\n",
    "! pip install jiwer\n",
    "!pip install  gdown\n",
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 13gKcDfU0N1VuXtRM2dCFYBMEgYPXKeLf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/NeMo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/install_beamsearch_decoders.sh\n",
    "#!/usr/bin/env bash\n",
    "# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Use this script to install KenLM, OpenSeq2Seq decoder, Flashlight decoder\n",
    "shopt -s expand_aliases\n",
    "\n",
    "NEMO_PATH=/kaggle/working/NeMo  # Path to NeMo folder: /workspace/nemo if you use NeMo/Dockerfile\n",
    "if [ \"$#\" -eq 1 ]; then\n",
    "  NEMO_PATH=$1\n",
    "fi\n",
    "KENLM_MAX_ORDER=10 # Maximum order of KenLM model, also specified in the setup_os2s_decoders.py\n",
    "\n",
    "if [ -d \"$NEMO_PATH\" ]; then\n",
    "  echo \"The folder '$NEMO_PATH' exists.\"\n",
    "else\n",
    "  echo \"Error: The folder '$NEMO_PATH' does not exist. Specify it as a first command line positional argument!\"\n",
    "  exit 1\n",
    "fi\n",
    "cd $NEMO_PATH\n",
    "\n",
    "if [ $(id -u) -eq 0 ]; then\n",
    "  alias aptupdate='apt-get update'\n",
    "  alias b2install='./b2'\n",
    "else\n",
    "  alias aptupdate='sudo apt-get update'\n",
    "  alias b2install='sudo ./b2'\n",
    "fi\n",
    "\n",
    "aptupdate && apt-get upgrade -y && apt-get install -y swig liblzma-dev && rm -rf /var/lib/apt/lists/* # liblzma needed for flashlight decoder\n",
    "\n",
    "# install Boost package for KenLM\n",
    "wget https://boostorg.jfrog.io/artifactory/main/release/1.80.0/source/boost_1_80_0.tar.bz2 --no-check-certificate && tar --bzip2 -xf $NEMO_PATH/boost_1_80_0.tar.bz2 && cd boost_1_80_0 && ./bootstrap.sh && b2install --layout=tagged link=static,shared threading=multi,single install -j4 && cd .. || echo FAILURE\n",
    "export BOOST_ROOT=$NEMO_PATH/boost_1_80_0\n",
    "\n",
    "git clone https://github.com/NVIDIA/OpenSeq2Seq\n",
    "cd OpenSeq2Seq\n",
    "git checkout ctc-decoders\n",
    "cd ..\n",
    "mv OpenSeq2Seq/decoders $NEMO_PATH/\n",
    "rm -rf OpenSeq2Seq\n",
    "cd $NEMO_PATH/decoders\n",
    "cp $NEMO_PATH/scripts/installers/setup_os2s_decoders.py ./setup.py\n",
    "./setup.sh\n",
    "\n",
    "# install KenLM\n",
    "cd $NEMO_PATH/decoders/kenlm/build && cmake -DKENLM_MAX_ORDER=$KENLM_MAX_ORDER .. && make -j2\n",
    "cd $NEMO_PATH/decoders/kenlm\n",
    "python setup.py install --max_order=$KENLM_MAX_ORDER\n",
    "export KENLM_LIB=$NEMO_PATH/decoders/kenlm/build/bin\n",
    "export KENLM_ROOT=$NEMO_PATH/decoders/kenlm\n",
    "cd ..\n",
    "\n",
    "# install Flashlight\n",
    "git clone https://github.com/flashlight/text && cd text\n",
    "python setup.py bdist_wheel\n",
    "pip install dist/*.whl\n",
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/install_beamsearch_decoders.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/train_kenlm.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
    "import subprocess\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "from omegaconf import MISSING\n",
    "\n",
    "# Update the Python path to include the scripts directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..')))\n",
    "\n",
    "from scripts.asr_language_modeling.ngram_lm import kenlm_utils\n",
    "\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "\n",
    "\"\"\"\n",
    "NeMo's beam search decoders only support char-level encodings. In order to make it work with BPE-level encodings, we\n",
    "use a trick to encode the sub-word tokens of the training data as unicode characters and train a char-level KenLM. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainKenlmConfig:\n",
    "    \"\"\"\n",
    "    Train an N-gram language model with KenLM to be used with beam search decoder of ASR models.\n",
    "    \"\"\"\n",
    "\n",
    "    train_paths: List[\n",
    "        str\n",
    "    ] = MISSING  # List of training files or folders. Files can be a plain text file or \".json\" manifest or \".json.gz\". Example: [/path/to/manifest/file,/path/to/folder]\n",
    "\n",
    "    nemo_model_file: str = MISSING  # The path to '.nemo' file of the ASR model, or name of a pretrained NeMo model\n",
    "    kenlm_model_file: str = MISSING  # The path to store the KenLM binary model file\n",
    "    ngram_length: int = MISSING  # The order of N-gram LM\n",
    "    kenlm_bin_path: str = MISSING  # The path to the bin folder of KenLM.\n",
    "\n",
    "    preserve_arpa: bool = False  # Whether to preserve the intermediate ARPA file.\n",
    "    ngram_prune: List[int] = field(\n",
    "        default_factory=lambda: [0]\n",
    "    )  # List of digits to prune Ngram. Example: [0,0,1]. See Pruning section on the https://kheafield.com/code/kenlm/estimation\n",
    "    cache_path: str = \"\"  # Cache path to save tokenized files.\n",
    "    verbose: int = 1  # Verbose level, default is 1.\n",
    "\n",
    "\n",
    "@hydra_runner(config_path=None, config_name='TrainKenlmConfig', schema=TrainKenlmConfig)\n",
    "def main(args: TrainKenlmConfig):\n",
    "    train_paths = kenlm_utils.get_train_list(args.train_paths)\n",
    "\n",
    "    if isinstance(args.ngram_prune, str):\n",
    "        args.ngram_prune = [args.ngram_prune]\n",
    "\n",
    "    tokenizer, encoding_level, is_aggregate_tokenizer = kenlm_utils.setup_tokenizer(args.nemo_model_file)\n",
    "\n",
    "    if encoding_level == \"subword\":\n",
    "        discount_arg = \"--discount_fallback\"  # --discount_fallback is needed for training KenLM for BPE-based models\n",
    "    else:\n",
    "        discount_arg = \"\"\n",
    "\n",
    "    arpa_file = f\"{args.kenlm_model_file}.tmp.arpa\"\n",
    "    \"\"\" LMPLZ ARGUMENT SETUP \"\"\"\n",
    "    kenlm_args = [\n",
    "        os.path.join(args.kenlm_bin_path, 'lmplz'),\n",
    "        \"-o\",\n",
    "        str(args.ngram_length),\n",
    "        \"--arpa\",\n",
    "        arpa_file,\n",
    "        discount_arg,\n",
    "        \"--prune\",\n",
    "    ] + [str(n) for n in args.ngram_prune]\n",
    "\n",
    "    if args.cache_path:\n",
    "        if not os.path.exists(args.cache_path):\n",
    "            os.makedirs(args.cache_path, exist_ok=True)\n",
    "\n",
    "        \"\"\" DATASET SETUP \"\"\"\n",
    "        encoded_train_files = []\n",
    "        for file_num, train_file in enumerate(train_paths):\n",
    "            logging.info(f\"Encoding the train file '{train_file}' number {file_num+1} out of {len(train_paths)} ...\")\n",
    "\n",
    "            cached_files = glob(os.path.join(args.cache_path, os.path.split(train_file)[1]) + \"*\")\n",
    "            encoded_train_file = os.path.join(args.cache_path, os.path.split(train_file)[1] + f\"_{file_num}.tmp.txt\")\n",
    "            if (\n",
    "                cached_files and cached_files[0] != encoded_train_file\n",
    "            ):  # cached_files exists but has another file name: f\"_{file_num}.tmp.txt\"\n",
    "                os.rename(cached_files[0], encoded_train_file)\n",
    "                logging.info(\"Rename\", cached_files[0], \"to\", encoded_train_file)\n",
    "\n",
    "            encoded_train_files.append(encoded_train_file)\n",
    "\n",
    "        kenlm_utils.iter_files(\n",
    "            source_path=train_paths,\n",
    "            dest_path=encoded_train_files,\n",
    "            tokenizer=tokenizer,\n",
    "            encoding_level=encoding_level,\n",
    "            is_aggregate_tokenizer=is_aggregate_tokenizer,\n",
    "            verbose=args.verbose,\n",
    "        )\n",
    "\n",
    "        first_process_args = [\"cat\"] + encoded_train_files\n",
    "        first_process = subprocess.Popen(first_process_args, stdout=subprocess.PIPE, stderr=sys.stderr)\n",
    "\n",
    "        logging.info(f\"Running lmplz command \\n\\n{' '.join(kenlm_args)}\\n\\n\")\n",
    "        kenlm_p = subprocess.run(\n",
    "            kenlm_args,\n",
    "            stdin=first_process.stdout,\n",
    "            capture_output=False,\n",
    "            text=True,\n",
    "            stdout=sys.stdout,\n",
    "            stderr=sys.stderr,\n",
    "        )\n",
    "        first_process.wait()\n",
    "\n",
    "    else:\n",
    "        logging.info(f\"Running lmplz command \\n\\n{' '.join(kenlm_args)}\\n\\n\")\n",
    "        kenlm_p = subprocess.Popen(kenlm_args, stdout=sys.stdout, stdin=subprocess.PIPE, stderr=sys.stderr)\n",
    "\n",
    "        kenlm_utils.iter_files(\n",
    "            source_path=train_paths,\n",
    "            dest_path=kenlm_p.stdin,\n",
    "            tokenizer=tokenizer,\n",
    "            encoding_level=encoding_level,\n",
    "            is_aggregate_tokenizer=is_aggregate_tokenizer,\n",
    "            verbose=args.verbose,\n",
    "        )\n",
    "\n",
    "        kenlm_p.communicate()\n",
    "\n",
    "    if kenlm_p.returncode != 0:\n",
    "        raise RuntimeError(\"Training KenLM was not successful!\")\n",
    "\n",
    "    \"\"\" BINARY BUILD \"\"\"\n",
    "\n",
    "    kenlm_args = [\n",
    "        os.path.join(args.kenlm_bin_path, \"build_binary\"),\n",
    "        \"trie\",\n",
    "        arpa_file,\n",
    "        args.kenlm_model_file,\n",
    "    ]\n",
    "    logging.info(f\"Running binary_build command \\n\\n{' '.join(kenlm_args)}\\n\\n\")\n",
    "    ret = subprocess.run(kenlm_args, capture_output=False, text=True, stdout=sys.stdout, stderr=sys.stderr)\n",
    "\n",
    "    if ret.returncode != 0:\n",
    "        raise RuntimeError(\"Training KenLM was not successful!\")\n",
    "\n",
    "    if not args.preserve_arpa:\n",
    "        os.remove(arpa_file)\n",
    "        logging.info(f\"Deleted the arpa file '{arpa_file}'.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/train_kenlm.py nemo_model_file=\"/kaggle/working/final_asr_model.nemo\" \\\n",
    "                          train_paths=\"[\\\"/kaggle/input/dataset-ja/final_train.json\\\"]\" \\\n",
    "                          kenlm_bin_path=\"/kaggle/working/NeMo/decoders/kenlm/build/bin\" \\\n",
    "                          kenlm_model_file=\"/kaggle/working/kenlm_model.binary\" \\\n",
    "                          ngram_length=6 \\\n",
    "                          preserve_arpa=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load /kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_ctc.py\n",
    "import contextlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
    "import pickle\n",
    "import tempfile\n",
    "from dataclasses import dataclass, field, is_dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import MISSING, OmegaConf\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.parts.submodules import rnnt_beam_decoding\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "\n",
    "# fmt: off\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvalBeamSearchNGramConfig:\n",
    "    nemo_model_file: str = MISSING\n",
    "    input_manifest: str = MISSING\n",
    "    decoding_mode: str = MISSING  # Add this line\n",
    "    kenlm_model_file: Optional[str] = None\n",
    "    preds_output_folder: Optional[str] = None\n",
    "    probs_cache_file: Optional[str] = None\n",
    "\n",
    "    acoustic_batch_size: int = 128\n",
    "    beam_batch_size: int = 128\n",
    "    device: str = \"cuda\"\n",
    "    use_amp: bool = False\n",
    "    num_workers: int = 1\n",
    "\n",
    "    decoding_strategy: str = \"beam\"\n",
    "    beam_width: List[int] = field(default_factory=lambda: [128, 256])\n",
    "    beam_alpha: List[float] = field(default_factory=lambda: [0.5, 1.0])\n",
    "    maes_prefix_alpha: List[int] = field(default_factory=lambda: [2])\n",
    "    maes_expansion_gamma: List[float] = field(default_factory=lambda: [2.3])\n",
    "    hat_subtract_ilm: bool = False\n",
    "    hat_ilm_weight: List[float] = field(default_factory=lambda: [0.0])\n",
    "\n",
    "    decoding: rnnt_beam_decoding.BeamRNNTInferConfig = field(default_factory=lambda: rnnt_beam_decoding.BeamRNNTInferConfig(beam_size=128))\n",
    "\n",
    "\n",
    "# fmt: on\n",
    "\n",
    "\n",
    "def decoding_step(\n",
    "    model: nemo_asr.models.ASRModel,\n",
    "    cfg: EvalBeamSearchNGramConfig,\n",
    "    all_probs: List[torch.Tensor],\n",
    "    target_transcripts: List[str],\n",
    "    preds_output_file: str = None,\n",
    "    beam_batch_size: int = 128,\n",
    "    progress_bar: bool = True,\n",
    "):\n",
    "    level = logging.getEffectiveLevel()\n",
    "    logging.setLevel(logging.CRITICAL)\n",
    "    model.change_decoding_strategy(None)\n",
    "\n",
    "    cfg.decoding.hat_ilm_weight = cfg.decoding.hat_ilm_weight * cfg.hat_subtract_ilm\n",
    "    cfg.decoding.return_best_hypothesis = False\n",
    "    cfg.decoding.ngram_lm_model = cfg.kenlm_model_file\n",
    "    cfg.decoding.hat_subtract_ilm = cfg.hat_subtract_ilm\n",
    "\n",
    "    model.cfg.decoding.strategy = cfg.decoding_strategy\n",
    "    model.cfg.decoding.beam = cfg.decoding\n",
    "    model.change_decoding_strategy(model.cfg.decoding)\n",
    "    logging.setLevel(level)\n",
    "\n",
    "    wer_dist_first = cer_dist_first = 0\n",
    "    wer_dist_best = cer_dist_best = 0\n",
    "    words_count = 0\n",
    "    chars_count = 0\n",
    "    sample_idx = 0\n",
    "    if preds_output_file:\n",
    "        out_file = open(preds_output_file, 'w', encoding='utf_8', newline='\\n')\n",
    "\n",
    "    if progress_bar:\n",
    "        if cfg.decoding_strategy == \"greedy_batch\":\n",
    "            description = \"Greedy_batch decoding..\"\n",
    "        else:\n",
    "            description = f\"{cfg.decoding_strategy} decoding with bw={cfg.decoding.beam_size}, ba={cfg.decoding.ngram_lm_alpha}, ma={cfg.decoding.maes_prefix_alpha}, mg={cfg.decoding.maes_expansion_gamma}, hat_ilmw={cfg.decoding.hat_ilm_weight}\"\n",
    "        it = tqdm(range(int(np.ceil(len(all_probs) / beam_batch_size))), desc=description, ncols=120)\n",
    "    else:\n",
    "        it = range(int(np.ceil(len(all_probs) / beam_batch_size)))\n",
    "    for batch_idx in it:\n",
    "        probs_batch = all_probs[batch_idx * beam_batch_size : (batch_idx + 1) * beam_batch_size]\n",
    "        probs_lens = torch.tensor([prob.shape[-1] for prob in probs_batch])\n",
    "        with torch.no_grad():\n",
    "            packed_batch = torch.zeros(len(probs_batch), probs_batch[0].shape[0], max(probs_lens), device='cpu')\n",
    "            for prob_index in range(len(probs_batch)):\n",
    "                packed_batch[prob_index, :, : probs_lens[prob_index]] = torch.tensor(\n",
    "                    probs_batch[prob_index].unsqueeze(0), device=packed_batch.device, dtype=packed_batch.dtype\n",
    "                )\n",
    "            best_hyp_batch, beams_batch = model.decoding.rnnt_decoder_predictions_tensor(\n",
    "                packed_batch, probs_lens, return_hypotheses=True,\n",
    "            )\n",
    "        if cfg.decoding_strategy == \"greedy_batch\":\n",
    "            beams_batch = [[x] for x in best_hyp_batch]\n",
    "\n",
    "        for beams_idx, beams in enumerate(beams_batch):\n",
    "            target = target_transcripts[sample_idx + beams_idx]\n",
    "            target_split_w = target.split()\n",
    "            target_split_c = list(target)\n",
    "            words_count += len(target_split_w)\n",
    "            chars_count += len(target_split_c)\n",
    "            wer_dist_min = cer_dist_min = 10000\n",
    "            for candidate_idx, candidate in enumerate(beams):\n",
    "                pred_text = candidate.text\n",
    "                pred_split_w = pred_text.split()\n",
    "                wer_dist = editdistance.eval(target_split_w, pred_split_w)\n",
    "                pred_split_c = list(pred_text)\n",
    "                cer_dist = editdistance.eval(target_split_c, pred_split_c)\n",
    "\n",
    "                wer_dist_min = min(wer_dist_min, wer_dist)\n",
    "                cer_dist_min = min(cer_dist_min, cer_dist)\n",
    "\n",
    "                if candidate_idx == 0:\n",
    "                    wer_dist_first += wer_dist\n",
    "                    cer_dist_first += cer_dist\n",
    "\n",
    "                score = candidate.score\n",
    "                if preds_output_file:\n",
    "                    out_file.write('{}\\t{}\\n'.format(pred_text, score))\n",
    "            wer_dist_best += wer_dist_min\n",
    "            cer_dist_best += cer_dist_min\n",
    "        sample_idx += len(probs_batch)\n",
    "\n",
    "    if cfg.decoding_strategy == \"greedy_batch\":\n",
    "        return wer_dist_first / words_count, cer_dist_first / chars_count\n",
    "\n",
    "    if preds_output_file:\n",
    "        out_file.close()\n",
    "        logging.info(f\"Stored the predictions of {cfg.decoding_strategy} decoding at '{preds_output_file}'.\")\n",
    "\n",
    "    if cfg.decoding.ngram_lm_model:\n",
    "        logging.info(\n",
    "            f\"WER/CER with {cfg.decoding_strategy} decoding and N-gram model = {wer_dist_first / words_count:.2%}/{cer_dist_first / chars_count:.2%}\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\n",
    "            f\"WER/CER with {cfg.decoding_strategy} decoding = {wer_dist_first / words_count:.2%}/{cer_dist_first / chars_count:.2%}\"\n",
    "        )\n",
    "    logging.info(\n",
    "        f\"Oracle WER/CER in candidates with perfect LM= {wer_dist_best / words_count:.2%}/{cer_dist_best / chars_count:.2%}\"\n",
    "    )\n",
    "    logging.info(f\"=================================================================================\")\n",
    "\n",
    "    return wer_dist_first / words_count, cer_dist_first / chars_count\n",
    "\n",
    "\n",
    "@hydra_runner(config_path=None, config_name='EvalBeamSearchNGramConfig', schema=EvalBeamSearchNGramConfig)\n",
    "def main(cfg: EvalBeamSearchNGramConfig):\n",
    "    if is_dataclass(cfg):\n",
    "        cfg = OmegaConf.structured(cfg)  # type: EvalBeamSearchNGramConfig\n",
    "\n",
    "    valid_decoding_strategis = [\"greedy_batch\", \"beam\", \"tsd\", \"alsd\", \"maes\"]\n",
    "    if cfg.decoding_strategy not in valid_decoding_strategis:\n",
    "        raise ValueError(\n",
    "            f\"Given decoding_strategy={cfg.decoding_strategy} is invalid. Available options are :\\n\"\n",
    "            f\"{valid_decoding_strategis}\"\n",
    "        )\n",
    "\n",
    "    if cfg.nemo_model_file.endswith('.nemo'):\n",
    "        asr_model = nemo_asr.models.ASRModel.restore_from(cfg.nemo_model_file, map_location=torch.device(cfg.device))\n",
    "    else:\n",
    "        logging.warning(\n",
    "            \"nemo_model_file does not end with .nemo, therefore trying to load a pretrained model with this name.\"\n",
    "        )\n",
    "        asr_model = nemo_asr.models.ASRModel.from_pretrained(\n",
    "            cfg.nemo_model_file, map_location=torch.device(cfg.device)\n",
    "        )\n",
    "\n",
    "    if cfg.kenlm_model_file:\n",
    "        if not os.path.exists(cfg.kenlm_model_file):\n",
    "            raise FileNotFoundError(f\"Could not find the KenLM model file '{cfg.kenlm_model_file}'.\")\n",
    "        if cfg.decoding_strategy != \"maes\":\n",
    "            raise ValueError(f\"Decoding with kenlm model is supported only for maes decoding algorithm.\")\n",
    "        lm_path = cfg.kenlm_model_file\n",
    "    else:\n",
    "        lm_path = None\n",
    "        cfg.beam_alpha = [0.0]\n",
    "    if cfg.hat_subtract_ilm:\n",
    "        assert lm_path, \"kenlm must be set for hat internal lm subtraction\"\n",
    "\n",
    "    if cfg.decoding_strategy != \"maes\":\n",
    "        cfg.maes_expansion_gamma = [1.0]\n",
    "        cfg.maes_prefix_alpha = [1.0]\n",
    "\n",
    "    if cfg.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        logging.warning(\"You have set device=cuda but no CUDA devices found. Setting device=cpu instead.\")\n",
    "        cfg.device = \"cpu\"\n",
    "    elif cfg.device == \"cpu\" and torch.cuda.is_available():\n",
    "        logging.warning(\"You have set device=cpu, but there are available CUDA devices. Using CPU for inference.\")\n",
    "\n",
    "    if cfg.probs_cache_file and os.path.exists(cfg.probs_cache_file):\n",
    "        logging.info(f\"Restoring the probs cache from '{cfg.probs_cache_file}'.\")\n",
    "        with open(cfg.probs_cache_file, \"rb\") as cache_f:\n",
    "            probs_dict = pickle.load(cache_f)\n",
    "    else:\n",
    "        logging.info(f\"Computing and caching the probabilities of samples in '{cfg.input_manifest}'.\")\n",
    "        probs_dict = {}\n",
    "        for test_batch in asr_model.transcribe(\n",
    "            paths2audio_files=cfg.input_manifest,\n",
    "            batch_size=cfg.acoustic_batch_size,\n",
    "            num_workers=cfg.num_workers,\n",
    "            return_hypotheses=False,\n",
    "            use_amp=cfg.use_amp,\n",
    "            channel_selector=None,\n",
    "        ):\n",
    "            for test_pred in test_batch:\n",
    "                probs_dict[test_pred.audio_file] = (test_pred.feature_probs.cpu(), test_pred.tokens.cpu())\n",
    "        if cfg.probs_cache_file:\n",
    "            with open(cfg.probs_cache_file, \"wb\") as cache_f:\n",
    "                pickle.dump(probs_dict, cache_f)\n",
    "\n",
    "    for grid_idx, params in enumerate(ParameterGrid(cfg.dict_config)):\n",
    "        for k, v in params.items():\n",
    "            OmegaConf.update(cfg, k, v, merge=True)\n",
    "\n",
    "        preds_output_file = None\n",
    "        if cfg.preds_output_folder:\n",
    "            preds_output_file = os.path.join(\n",
    "                cfg.preds_output_folder,\n",
    "                f\"beam_search_preds_bs={cfg.decoding.beam_size}_ba={cfg.decoding.ngram_lm_alpha}_ma={cfg.decoding.maes_prefix_alpha}_mg={cfg.decoding.maes_expansion_gamma}_ilmw={cfg.decoding.hat_ilm_weight}.txt\",\n",
    "            )\n",
    "            os.makedirs(cfg.preds_output_folder, exist_ok=True)\n",
    "\n",
    "        all_probs = []\n",
    "        target_transcripts = []\n",
    "        for file, (probs, _) in probs_dict.items():\n",
    "            all_probs.append(probs)\n",
    "            target_transcripts.append(file)\n",
    "\n",
    "        wer, cer = decoding_step(\n",
    "            asr_model,\n",
    "            cfg,\n",
    "            all_probs,\n",
    "            target_transcripts,\n",
    "            preds_output_file=preds_output_file,\n",
    "            beam_batch_size=cfg.beam_batch_size,\n",
    "        )\n",
    "        logging.info(f\"WER/CER = {wer:.2%}/{cer:.2%}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/NeMo/scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_ctc.py nemo_model_file=\"/kaggle/working/final_asr_model.nemo\" \\\n",
    "       input_manifest=\"/kaggle/input/dataset-ja/banana.json\" \\\n",
    "       kenlm_model_file=\"/kaggle/working/kenlm_model.binary\" \\\n",
    "       beam_width=\"[128, 256]\" \\\n",
    "       beam_alpha=\"[0.5, 1.0]\" \\\n",
    "       beam_beta=\"[0.5, 1.0]\" \\\n",
    "       preds_output_folder=\"/kaggle/working/predictions\" \\\n",
    "       probs_cache_file=null \\\n",
    "       decoding_mode=beamsearch_ngram \\\n",
    "       decoding_strategy=\"beam\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
