{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8825323,"sourceType":"datasetVersion","datasetId":5235235},{"sourceId":8860832,"sourceType":"datasetVersion","datasetId":5334664}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install wget\n!apt-get install -y sox libsndfile1 ffmpeg\n!pip install text-unidecode\n!pip install matplotlib>=3.3.2\n!pip install pytorch_lightning\n## Install NeMo\nBRANCH = 'r2.0.0rc0'\n!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH  #egg=nemo_toolkit[all] \n## Grab the config we'll use in this example","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install editdistance\n!pip install webdataset\n!pip install pyannote.metrics\n!pip install einops\n!pip install pyannote.core\n!pip install inflect\n!pip install hydra.core\n!pip install lhotse\n!pip install numpy soundfile joblib omegaconf lhotse\n!pip install jiwer\n!pip install  gdown\n#pip install -r /kaggle/working/SphinxSpeech/requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 13gKcDfU0N1VuXtRM2dCFYBMEgYPXKeLf ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the path to your ZIP file\nzip_file_path = '/kaggle/working/tokenizer_spe_bpe_v128.zip'\nunzip_dir = '/kaggle/working/tokenizers_v2/'\n\n# Create the directory to unzip into\nos.makedirs(unzip_dir, exist_ok=True)\n\n# Unzip the file\n!unzip -q {zip_file_path} -d {unzip_dir}\n\n# Check the contents of the directory to ensure the files were unzipped\nos.listdir(unzip_dir)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir configs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/configs/conformer_ctc_bpe.yaml\nname: \"Conformer-CTC-BPE\"\n\nmodel:\n  sample_rate: 16000\n  log_prediction: true\n  ctc_reduction: 'mean_batch'\n  skip_nan_grad: false\n\n  train_ds:\n    manifest_filepath: \"/kaggle/input/dataset-ja/final_train.json\"\n    sample_rate: ${model.sample_rate}\n    batch_size: 32  # Increased batch size\n    shuffle: true\n    num_workers: 4  # Reduced to suggested maximum workers\n    pin_memory: true\n    max_duration: 28\n    min_duration: 0.384\n    is_tarred: false\n    tarred_audio_filepaths: null\n    shuffle_n: 2048\n    bucketing_strategy: \"synced_randomized\"\n    bucketing_batch_size: null\n\n  validation_ds:\n    manifest_filepath: \"/kaggle/input/dataset-ja/banana.json\"\n    sample_rate: ${model.sample_rate}\n    batch_size: 32  # Increased batch size\n    shuffle: false\n    use_start_end_token: false\n    num_workers: 4  # Reduced to suggested maximum workers\n    pin_memory: true\n\n  test_ds:\n    manifest_filepath: \"/kaggle/input/dataset-ja/final_test.json\"\n    sample_rate: ${model.sample_rate}\n    batch_size: 32  # Increased batch size\n    shuffle: false\n    use_start_end_token: false\n    num_workers: 4  # Reduced to suggested maximum workers\n    pin_memory: true\n\n  tokenizer:\n    dir: \"/kaggle/working/tokenizers_v2/tokenizer_spe_bpe_v128\"\n    type: bpe\n\n  preprocessor:\n    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n    sample_rate: ${model.sample_rate}\n    normalize: \"per_feature\"\n    window_size: 0.025\n    window_stride: 0.01\n    window: \"hann\"\n    features: 80\n    n_fft: 512\n    log: true\n    frame_splicing: 1\n    dither: 0.00001\n    pad_to: 0\n    pad_value: 0.0\n\n  spec_augment:\n    _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n    freq_masks: 1  # Slight reduction\n    time_masks: 2  # Slight reduction\n    freq_width: 27\n    time_width: 0.05\n\n  encoder:\n    _target_: nemo.collections.asr.modules.ConformerEncoder\n    feat_in: ${model.preprocessor.features}\n    feat_out: -1\n    n_layers: 16\n    d_model: 176\n    subsampling: striding\n    subsampling_factor: 4\n    subsampling_conv_channels: -1\n    causal_downsampling: false\n    ff_expansion_factor: 4\n    self_attention_model: rel_pos\n    n_heads: 4\n    att_context_size: [-1, -1]\n    att_context_style: regular\n    xscaling: true\n    untie_biases: true\n    pos_emb_max_len: 5000\n    conv_kernel_size: 31\n    conv_norm_type: 'batch_norm'\n    conv_context_size: null\n    dropout: 0.1\n    dropout_pre_encoder: 0.1\n    dropout_emb: 0.0\n    dropout_att: 0.1\n    stochastic_depth_drop_prob: 0.0\n    stochastic_depth_mode: linear\n    stochastic_depth_start_layer: 1\n\n  decoder:\n    _target_: nemo.collections.asr.modules.ConvASRDecoder\n    feat_in: null\n    num_classes: -1\n    vocabulary: []\n\n  interctc:\n    loss_weights: []\n    apply_at_layers: []\n\n  optim:\n    name: adamw\n    lr: 5.0\n    betas: [0.9, 0.98]\n    weight_decay: 1e-3\n\n    sched:\n      name: NoamAnnealing\n      d_model: ${model.encoder.d_model}\n      warmup_steps: 10000\n      min_lr: 1e-6\n\ntrainer:\n  devices: -1\n  num_nodes: 1\n  max_epochs: 5\n  max_steps: -1\n  val_check_interval: 1.0\n  accelerator: auto\n  strategy: ddp\n  accumulate_grad_batches: 2  # Gradient accumulation\n  gradient_clip_val: 0.0\n  precision: 16  # Mixed precision training\n  log_every_n_steps: 50  # Reduced logging frequency\n  enable_progress_bar: True\n  num_sanity_val_steps: 0\n  check_val_every_n_epoch: 1\n  sync_batchnorm: false  # Disable Sync BatchNorm\n  enable_checkpointing: False\n  logger: false\n  benchmark: false\n\nexp_manager:\n  exp_dir: \"/kaggle/working/results\"\n  name: ${name}\n  create_tensorboard_logger: true\n  create_checkpoint_callback: true\n  checkpoint_callback_params:\n    monitor: \"val_wer\"\n    mode: \"min\"\n    save_top_k: 1  # Save only the best checkpoint\n    always_save_nemo: True\n\n  resume_if_exists: false\n  resume_ignore_no_checkpoint: false\n  create_wandb_logger: false\n  wandb_logger_kwargs:\n    name: null\n    project: null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!touch speech_to_text_ctc_bpe.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile speech_to_text_ctc_bpe.py\n\n\nimport pytorch_lightning as pl\nfrom omegaconf import OmegaConf\n\nfrom nemo.collections.asr.models.ctc_bpe_models import EncDecCTCModelBPE\nfrom nemo.core.config import hydra_runner\nfrom nemo.utils import logging\nfrom nemo.utils.exp_manager import exp_manager\n\n\n@hydra_runner(config_path=\"/kaggle/working/configs/\", config_name=\"conformer_ctc_bpe\")\ndef main(cfg):\n    logging.info(f'Hydra config: {OmegaConf.to_yaml(cfg)}')\n\n    trainer = pl.Trainer(**cfg.trainer)\n    exp_manager(trainer, cfg.get(\"exp_manager\", None))\n    asr_model = EncDecCTCModelBPE(cfg=cfg.model, trainer=trainer)\n\n    # Initialize the weights of the model from another model, if provided via config\n    asr_model.maybe_init_from_pretrained_checkpoint(cfg)\n\n    trainer.fit(asr_model)\n\n    if hasattr(cfg.model, 'test_ds') and cfg.model.test_ds.manifest_filepath is not None:\n        if asr_model.prepare_test(trainer):\n            trainer.test(asr_model)  \n    # Save the model\n    final_model_path = '/kaggle/working/final_asr_model.nemo'\n    asr_model.save_to(final_model_path)\n    logging.info(f'Model saved at {final_model_path}')\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['HYDRA_FULL_ERROR'] = '1'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/speech_to_text_ctc_bpe.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BRANCH = 'r2.0.0rc0'\n\n!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/transcribe_speech.py\n!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/speech_to_text_eval.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/configs/transcribe_speech.py \\\n  model_path=\"/kaggle/working/final_asr_model.nemo\" \\\n  dataset_manifest=\"/kaggle/input/dataset-ja/final_test.json\" \\\n  output_filename=\"/kaggle/working/test_with_predictions.json\" \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Calculate WER\n!python /kaggle/working/configs/speech_to_text_eval.py \\\n  dataset_manifest=\"/kaggle/working/test_with_predictions.json\" \\\n  use_cer=False \\\n  only_score_manifest=True\n\n# Calculate CER\n!python /kaggle/working/configs/speech_to_text_eval.py \\\n  dataset_manifest=\"/kaggle/working/test_with_predictions.json\" \\\n  use_cer=True \\\n  only_score_manifest=True","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}